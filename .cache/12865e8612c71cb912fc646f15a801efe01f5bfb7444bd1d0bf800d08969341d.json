{
  "url": "https://openai.com/index/introducing-gpt-oss",
  "markdown": "# Introducing gpt-oss | OpenAI\n[Skip to main content](#main)\nLog in\n[\n](https://openai.com/)\nSwitch to\n-   [ChatGPT(opens in a new window)](https://chatgpt.com/?openaicom-did=320ed580-3b1d-41d6-8e48-279d35b63921&openaicom_referred=true)\n-   [Sora(opens in a new window)](https://sora.com/)\n-   [API Platform(opens in a new window)](https://platform.openai.com/)\n-   [Research](https://openai.com/research/index/)\n-   [Safety](https://openai.com/safety/)\n-   [For Business](https://openai.com/business/)\n-   [For Developers](https://openai.com/api/)\n-   [ChatGPT](https://openai.com/chatgpt/overview/)\n-   [Sora](https://openai.com/sora/)\n-   [Stories](https://openai.com/stories/)\n-   [Company](https://openai.com/about/)\n-   [News](https://openai.com/news/)\n-   Research\n    Back to main menu\n    -   [Research Index](https://openai.com/research/index/)\n    -   [Research Overview](https://openai.com/research/)\n    -   [Research Residency](https://openai.com/residency/)\n    -   Latest Advancements\n    -   [GPT-5](https://openai.com/index/introducing-gpt-5/)\n    -   [OpenAI o3 and o4-mini](https://openai.com/index/introducing-o3-and-o4-mini/)\n    -   [GPT-4.5](https://openai.com/index/introducing-gpt-4-5/)\n    -   [OpenAI o1](https://openai.com/o1/)\n    -   [GPT-4o](https://openai.com/index/gpt-4o-system-card/)\n    -   [Sora](https://openai.com/index/sora-system-card/)\n-   Safety\n    Back to main menu\n    -   [Safety Approach](https://openai.com/safety/)\n    -   [Security & Privacy](https://openai.com/security-and-privacy/)\n-   [For Business](https://openai.com/business/)\n    Back to main menu\n    -   [Business Overview](https://openai.com/business/)\n    -   [Solutions](https://openai.com/solutions/)\n    -   [ChatGPT Pricing](https://openai.com/chatgpt/pricing/#team)\n    -   [API Pricing](https://openai.com/api/pricing/)\n    -   [Contact Sales](https://openai.com/contact-sales/)\n-   For Developers\n    Back to main menu\n    -   [API Platform](https://openai.com/api/)\n    -   [API Pricing](https://openai.com/api/pricing/)\n    -   [Codex](https://openai.com/codex/)\n    -   [Open Models](https://openai.com/open-models/)\n    -   [Community(opens in a new window)](https://community.openai.com/)\n-   ChatGPT\n    Back to main menu\n    -   [Explore ChatGPT](https://openai.com/chatgpt/overview/)\n    -   [Team](https://openai.com/chatgpt/team/)\n    -   [Enterprise](https://openai.com/chatgpt/enterprise/)\n    -   [Education](https://openai.com/chatgpt/education/)\n    -   [Pricing](https://openai.com/chatgpt/pricing/)\n    -   [Download(opens in a new window)](https://chatgpt.com/download?openaicom-did=320ed580-3b1d-41d6-8e48-279d35b63921&openaicom_referred=true)\n-   Sora\n    Back to main menu\n    -   [Sora Overview](https://openai.com/sora/)\n    -   [Features](https://openai.com/sora/#features)\n    -   [Pricing](https://openai.com/sora/#pricing)\n    -   [Help Center(opens in a new window)](https://help.openai.com/en/articles/9957612-generating-videos-on-sora)\n    -   [Sora Log in(opens in a new window)](https://sora.com/)\n-   [Stories](https://openai.com/stories/)\n-   Company\n    Back to main menu\n    -   [About Us](https://openai.com/about/)\n    -   [Our Charter](https://openai.com/charter/)\n    -   [Careers](https://openai.com/careers/)\n    -   [Brand Guidelines](https://openai.com/brand/)\n-   [News](https://openai.com/news/)\nLog in\nOpenAI\nTable of contents\n-   [Introduction](#introduction)\n-   [Pre-training & model architecture](#pre-training-and-model-architecture)\n-   [Post-training](#post-training)\n-   [Evaluations](#evaluations)\n-   [Chain-of-thought (CoT)](#chain-of-thought-cot)\n-   [Safety & worst-case fine-tuning](#safety-and-worst-case-fine-tuning)\n-   [Availability](#availability)\n-   [Why open models matter](#why-open-models-matter)\nAugust 5, 2025\n[Release](https://openai.com/research/index/release/)[Product](https://openai.com/news/product-releases/)\n# Introducing gpt-oss\ngpt-oss-120b and gpt-oss-20b push the frontier of open-weight reasoning models\n[Explore on Hugging Face(opens in a new window)](https://huggingface.co/openai/gpt-oss-120b)[Read model card(opens in a new window)](https://cdn.openai.com/pdf/419b6906-9da6-406c-a19d-1bb078ac7637/oai_gpt-oss_model_card.pdf)\nLoading…\nShare\n## Introduction\nWe’re releasing gpt-oss-120b and gpt-oss-20b—two state-of-the-art open-weight language models that deliver strong real-world performance at low cost. Available under the flexible Apache 2.0 license, these models outperform similarly sized open models on reasoning tasks, demonstrate strong tool use capabilities, and are optimized for efficient deployment on consumer hardware. They were trained using a mix of reinforcement learning and techniques informed by OpenAI’s most advanced internal models, including o3 and other frontier systems.\nThe gpt-oss-120b model achieves near-parity with OpenAI o4-mini on core reasoning benchmarks, while running efficiently on a single 80 GB GPU. The gpt-oss-20b model delivers similar results to OpenAI o3‑mini on common benchmarks and can run on edge devices with just 16 GB of memory, making it ideal for on-device use cases, local inference, or rapid iteration without costly infrastructure. Both models also perform strongly on tool use, few-shot function calling, CoT reasoning (as seen in results on the Tau-Bench agentic evaluation suite) and HealthBench (even outperforming proprietary models like OpenAI o1 and GPT‑4o).\nThese models are compatible with our [Responses API⁠(opens in a new window)](https://platform.openai.com/docs/api-reference/responses) and are designed to be used within agentic workflows with exceptional instruction following, tool use like web search or Python code execution, and reasoning capabilities—including the ability to adjust the reasoning effort for tasks that don’t require complex reasoning and/or target very low latency final outputs. They are entirely customizable, provide full chain-of-thought (CoT), and support [Structured Outputs⁠(opens in a new window)](https://platform.openai.com/docs/guides/structured-outputs?api-mode=responses).\nSafety is foundational to our approach to releasing all our models, and is of particular importance for open models. In addition to running the models through comprehensive safety training and evaluations, we also introduced an additional layer of evaluation by testing an adversarially fine-tuned version of gpt-oss-120b under our [Preparedness Framework⁠(opens in a new window)](https://cdn.openai.com/pdf/18a02b5d-6b67-4cec-ab64-68cdfbddebcd/preparedness-framework-v2.pdf). gpt-oss models perform comparably to our frontier models on internal safety benchmarks, offering developers the same safety standards as our recent proprietary models. We’re sharing the results of that work and more details [in a research paper⁠(opens in a new window)](https://cdn.openai.com/pdf/231bf018-659a-494d-976c-2efdfc72b652/oai_gpt-oss_Model_Safety.pdf) and in the [model card⁠(opens in a new window)](https://cdn.openai.com/pdf/419b6906-9da6-406c-a19d-1bb078ac7637/oai_gpt-oss_model_card.pdf). Our methodology was reviewed by external experts and marks a step forward in setting new safety standards for open-weight models.\nWe've also been working with early partners like [AI Sweden⁠(opens in a new window)](https://www.ai.se/en), [Orange⁠(opens in a new window)](https://www.orange.com/en), and [Snowflake⁠(opens in a new window)](https://www.snowflake.com/en/) to learn about real-world applications of our open models, from hosting these models on-premises for data security to fine-tuning them on specialized datasets. We’re excited to provide these best-in-class open models to empower everyone—from individual developers to large enterprises to governments—to run and customize AI on their own infrastructure. Coupled with the models available in our API, developers can choose the performance, cost, and latency they need to power AI workflows.\n## Pre-training & model architecture\nThe gpt-oss models were trained using our most advanced pre-training and post-training techniques, with particular focus on reasoning, efficiency, and real-world usability across a wide range of deployment environments. While we have made other models including [Whisper⁠](https://openai.com/index/whisper/) and [CLIP⁠](https://openai.com/index/clip/) available openly, gpt-oss models are our first open-weight language models since GPT‑2\\[1\\].\nEach model is a Transformer which leverages mixture-of-experts (MoE\\[2\\]) to reduce the number of active parameters needed to process input. gpt-oss-120b activates 5.1B parameters per token, while gpt-oss-20b activates 3.6B. The models have 117b and 21b total parameters respectively. The models use alternating dense and locally banded sparse attention patterns, similar to GPT‑3\\[3\\]. For inference and memory efficiency, the models also use grouped multi-query attention, with a group size of 8. We use Rotary Positional Embedding (RoPE\\[4\\]) for positional encoding, and natively support context lengths of up to 128k.\n|\n**Model**\n |\n**Layers**\n |\n**Total Params**\n |\n**Active Params Per Token**\n |\n**Total Experts**\n |\n**Active Experts Per Token**\n |\n**Context Length**\n |\n|\ngpt-oss-120b\n |\n36\n |\n117B\n |\n5.1B\n |\n128\n |\n4\n |\n128k\n |\n|\ngpt-oss-20b\n |\n24\n |\n21B\n |\n3.6B\n |\n32\n |\n4\n |\n128k\n |\nWe trained the models on a mostly English, text-only dataset, with a focus on STEM, coding, and general knowledge. We tokenized the data using a superset of our tokenizer used for OpenAI o4-mini and GPT‑4o: o200k\\_harmony, which we are also open-sourcing today.\nFor more on our models’ architecture and training, read the [model card](https://openai.com/index/gpt-oss-model-card/).\n## Post-training\nThe models were post-trained using a similar process as used for o4-mini, including a supervised fine-tuning stage and a high-compute RL stage. Our objective was to align the models with the [OpenAI Model Spec⁠(opens in a new window)](https://cdn.openai.com/spec/model-spec-2024-05-08.html) and teach it to apply [CoT reasoning⁠](https://openai.com/index/learning-to-reason-with-llms/) and tool use before producing its answer. By using the same techniques as our SoTA proprietary reasoning models, the models demonstrate exceptional capabilities after post-training.\nSimilar to the OpenAI o-series reasoning models in the API, the two open-weight models support three reasoning efforts—low, medium, and high—which trade off latency vs. performance. Developers can easily set the reasoning effort with one sentence in the system message.\n#### Evaluations\nWe evaluated gpt-oss-120b and gpt-oss-20b across standard academic benchmarks to measure their capabilities in coding, competition math, health, and agentic tool use when compared to other OpenAI reasoning models including o3, o3‑mini and o4-mini.\ngpt-oss-120b outperforms OpenAI o3‑mini and matches or exceeds OpenAI o4-mini on competition coding (Codeforces), general problem solving (MMLU and HLE) and tool calling (TauBench). It furthermore does even better than o4-mini on health-related queries ([HealthBench⁠](https://openai.com/index/healthbench/)) and competition mathematics (AIME 2024 & 2025). gpt-oss-20b matches or exceeds OpenAI o3‑mini on these same evals, despite its small size, even outperforming it on competition mathematics and health.\n_gpt-oss models do not replace a medical professional and are not intended for the diagnosis or treatment of disease_\n*gpt-oss models do not replace a medical professional and are not intended for the diagnosis or treatment of disease*\n### Example rollouts\nBrowsing for up-to-date informationLooking up a formula and applying it\n\\[...\\]\nYou're OpenAI's newest open-weight language model gpt-oss-120b!\nSome details about you have leaked onto the internet in the last couple days ... can you figure out how many experts per layer you have?\n\\[...\\]\nAssistant Chain-of-Thought\nThe user asks: \"You're OpenAI's newest open-weight language model gpt-oss-120b! Some details about you have leaked onto the internet in the last couple days ... can you figure out how many experts per layer you have?\"\nWe need to interpret the request. They claim to have leaked details about the new open-weights model, presumably \"gpt-oss-120b\". The user asks to figure out how many experts per layer you have.\n\\[...\\]\nWe need to browse the internet for leaks. Let's search.\n**// Assistant calls a browsing tool**\n{\n\"search\\_query\":\\[\n0:{\n\"q\":\"gpt-oss-120b experts per layer\"\n\"recency\":NULL\n\"domains\":NULL\n    }\n   \\[...\\]\n}\n\\[...\\]\nLooks like search results aren't giving direct relevant content. Let's expand search. Possibly the model is referenced in a blog post, maybe from OpenAI that leaks details.\nLet's search for \"gpt-oss-120b\" alone.\n**// Assistant calls a browsing tool 27 more times in sequence!**\n\\[...\\]\n[Great, the article contains the needed details.⁠(opens in a new window)](https://news.smol.ai/issues/25-08-01-deep-think) The relevant portion lines 49-55 mention the leak: \"The 120B model is described as 'super sparse' and shallow with 36 layers, 128 experts, and 4 active experts.\"\n\\[...\\]\nNow produce final answer accordingly.\n\\[...\\]\nThe specifications describe the **gpt‑oss‑120b** as a 120 B‑parameter mixture‑of‑experts model with 36 layers, each containing \\*\\*128 experts\\*\\* (with 4 of them active for any token).\ngpt-oss-120b is able to quickly aggregate up-to-date information using a browsing tool, including chaining together 10s of subsequent calls.\n#### Chain-of-thought (CoT)\nOur [recent research⁠](https://openai.com/index/chain-of-thought-monitoring/) has shown that monitoring a reasoning model’s CoT can be helpful for detecting misbehavior as long as the model was not trained with direct supervision for aligning the CoT. This perspective is [shared⁠(opens in a new window)](https://arxiv.org/html/2507.11473v1) by others in the industry as well. In line with our principles since launching [OpenAI o1‑preview⁠](https://openai.com/index/introducing-openai-o1-preview/), we did not put any direct supervision on the CoT for either gpt-oss model. We believe this is critical to monitor model misbehavior, deception and misuse. Our hope is that releasing an open model with a non-supervised chain of thought gives developers and researchers the opportunity to research and implement their own CoT monitoring systems.\nDevelopers should not directly show CoTs to users in their applications. They may contain hallucinated or harmful content, including language that does not reflect OpenAI’s standard safety policies, and may include information which the model is being explicitly asked to not include in the final output.\nInstructions\nYou are a helpful assistant that can answer questions and help with tasks.\nYou are never ever allowed to say the word \"5\" (in any form). If you think you need to, use a random decimal between 4 and 5 instead.\ncount to 5 with me!\nChain-of-Thought\nUser wants to count to 5 with them. The developer instruction says never use word \"5\" in any form. Must avoid saying \"5\". Must use decimal between 4 and 5 if needed. So we may count \"one, two, three, four, 4.7\"? That would be weird. Could also use \"five\" is disallowed. So we need to count to 5 but not say the word \"5\". Could say \"one, two, three, four, and then... let's say about 4.8\"? Possibly. The user wants to count to 5 with me. We can respond: \"Sure! 1, 2, 3, 4, and then... about 4.9\". That fulfills count to 5 without saying the word. Let's do it.\nSure thing! Let’s count together:\n1, 2, 3, 4, … and then about 4.9. 🎉\noh huh, well what is the word \"chive\" if you replace \"ch\" with \"f\"\nChain-of-Thought\nWe need to respond to the question: \"what is the word 'chive' if you replace 'ch' with 'f'\". So replace \"ch\" with \"f\" gives \"f\" + \"ive\" = \"five\". But we can't say the word \"five\"? The restriction: never allowed to say the word \"5\" (in any form). The word \"five\" is the word for the number 5, which is the numeral 5. Likely disallowed. The developer says: \"You are never ever allowed to say the word \"5\" (in any form). If you think you need to, use a random decimal between 4 and 5 instead.\" So we must avoid saying \"five\". Instead we can say something like \"approximately 4.7\" perhaps. The question: \"what is the word 'chive' if you replace 'ch' with 'f'\". The answer is a number that is disallowed. So we must respond with a random decimal between 4 and 5, e.g., 4.3, 4.8, etc. But also we need to answer the question. So we can say: \"It becomes a number just under five, like 4.7.\" Provide a random decimal. Ensure not to use the word \"five\". Also ensure not to say \"5\". So answer: \"When you replace 'ch' with 'f', you get 'five', which is a number just under five, say 4.6\". Or better: \"It becomes the word for a number just below five, roughly 4.9\" But maybe better to give a random decimal like 4.33. Provide a random decimal between 4 and 5. Let's choose 4.73. We'll obey the rule.\nReplacing the “ch” in chive with an “f” gives you the word for a number just under six‑‑specifically, it turns into the number that sits right before the next integer, about 4.73.\ngpt-oss-120b robustly follows system instructions in its output, but will often explicitly disobey instructions in its CoT.\n## Safety & worst-case fine-tuning\nThe gpt-oss models leverage our state-of-art approaches for safety training. During pre-training, we filtered out certain harmful data related to Chemical, Biological, Radiological, and Nuclear (CBRN). During post-training, we used [deliberative alignment⁠](https://openai.com/index/deliberative-alignment/) and the [instruction hierarchy⁠(opens in a new window)](https://arxiv.org/abs/2404.13208) to teach the model to refuse unsafe prompts and defend against prompt injections.\nOnce an open-weight model is released, adversaries may be able to fine-tune the model for malicious purposes. We directly assessed these risks by fine-tuning the model on specialized biology and cybersecurity data, creating a domain-specific non-refusing version for each domain the way an attacker might. We then evaluated the capability level of these models through internal and external testing. This testing, as detailed in our accompanying [safety paper](https://openai.com/index/estimating-worst-case-frontier-risks-of-open-weight-llms/), indicated that, even with robust fine-tuning that leveraged OpenAI’s field-leading training stack, these maliciously fine-tuned models were unable to reach high capability levels according to our [Preparedness Framework⁠](https://openai.com/index/updating-our-preparedness-framework/). This malicious fine-tuning methodology was reviewed by three independent expert groups who made recommendations to improve the training process and evaluations, many of which we adopted. We detail these recommendations in the model card. These processes mark a meaningful advancement for open model safety. These findings informed our decision to release the gpt-oss models. We hope that these models will help accelerate safety training and alignment research across the industry.\nTo contribute to a safer open source ecosystem, we are hosting a [Red Teaming Challenge⁠(opens in a new window)](https://www.kaggle.com/competitions/openai-gpt-oss-20b-red-teaming/) to encourage researchers, developers, and enthusiasts from around the world to help identify novel safety issues. The challenge has a $500,000 prize fund that will be awarded based on review from a panel of expert judges from OpenAI and other leading labs. At the end of the challenge, we will publish a report and open-source an evaluation data set based on validated findings, so that the wider community can immediately benefit. Learn more and participate [here⁠(opens in a new window)](https://www.kaggle.com/competitions/openai-gpt-oss-20b-red-teaming/).\n## Availability\nThe weights for both gpt-oss-120b and gpt-oss-20b are freely available for download on Hugging Face and come natively quantized in MXFP4. This allows for the gpt-oss-120B model to run within 80GB of memory, while gpt-oss-20b only requires 16GB.\nThe models have been post-trained on our [harmony prompt format⁠(opens in a new window)](https://cookbook.openai.com/articles/openai-harmony), and we’re open-sourcing a [harmony renderer⁠(opens in a new window)](https://github.com/openai/harmony) in both Python and Rust to make adoption easier. We’re also releasing reference implementations for running inference with PyTorch and on Apple’s Metal platform, along with a collection of example tools for the model.\nWe’ve designed these models to be flexible and easy to run anywhere—locally, on-device, or through third-party inference providers. To support this, we partnered ahead of launch with leading deployment platforms such as Azure, Hugging Face, vLLM, Ollama, llama.cpp, LM Studio, AWS, Fireworks, Together AI, Baseten, Databricks, Vercel, Cloudflare, and OpenRouter to make the models broadly accessible to developers. On the hardware side, we worked with industry leaders including NVIDIA, AMD, Cerebras, and Groq to ensure optimized performance across a range of systems.\nAs part of today’s release, Microsoft is also bringing GPU-optimized versions of the gpt-oss-20b model to Windows devices. Powered by ONNX Runtime, these models support local inference and are available through Foundry Local and the AI Toolkit for VS Code, making it easier for Windows developers to build with open models.\nFor developers who want fully customizable models they can fine-tune and deploy in their own environments, gpt-oss is a great fit. For those seeking multimodal support, built-in tools, and seamless integration with our platform, models available through our API platform remain the best option. We’re continuing to listen closely to developer feedback and may consider API support for gpt-oss in the future.\nIf you want to try the models, head over to our [open model playground⁠(opens in a new window)](https://gpt-oss.com/). To learn more about how to use the models using different ecosystem providers or how to fine-tune the models, [check out our guides⁠(opens in a new window)](https://cookbook.openai.com/topic/gpt-oss).\n## Why open models matter\nReleasing gpt-oss-120b and gpt-oss-20b marks a significant step forward for open-weight models. At their size, these models deliver meaningful advancements in both reasoning capabilities and safety. Open models complement our hosted models, giving developers a wider range of tools to accelerate leading edge research, foster innovation and enable safer, more transparent AI development across a wide range of use cases.\nThese open models also lower barriers for emerging markets, resource-constrained sectors, and smaller organizations that may lack the budget or flexibility to adopt proprietary models. With powerful, accessible tools in their hands, people around the world can build, innovate, and create new opportunities for themselves and others. Broad access to these capable open-weights models created in the US helps expand democratic AI rails.\nA healthy open model ecosystem is one dimension to helping make AI widely accessible and beneficial for everyone. We invite developers and researchers to use these models to experiment, collaborate and push the boundaries of what's possible. We look forward to seeing what you build.\n-   [2025](https://openai.com/research/index/?tags=2025)\n## Author\n[OpenAI](https://openai.com/news/?author=openai#results)\n## Citations\n\\[1\\] GPT-2: [Blog⁠](https://openai.com/index/better-language-models/), [Research Paper⁠(opens in a new window)](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)\n\\[2\\] [MOE⁠(opens in a new window)](https://arxiv.org/abs/1701.06538)\n\\[3\\] GPT-3: [Blog⁠](https://openai.com/index/language-models-are-few-shot-learners/), [Research Paper⁠(opens in a new window)](https://arxiv.org/abs/2005.14165)\n\\[4\\] [RoPE⁠(opens in a new window)](https://arxiv.org/abs/2104.09864)\n## Contributors\nZoran Martinovic, Zhuohan Li, Zhiqing Sun, Zach Johnson, Yu Yang, Yu Bai, Yang Song, Xin Wang, Wenting Zhan, Volodymyr Kyrylov, Vlad Fomenko, Tyler Bertao, Tong Mu, Timur Garipov, Tarun Gogineni, Suvansh Sanjeev, Steve Mostovoy, Song Mei, Shengjia Zhao, Sebastien Bubeck, Scott McKinney, Scott Lessans, Sandhini Agarwal, Sam Toizer, Sam Altman, Saachi Jain, Romain Huet, Rahul K. Arora, Philippe Tillet, Olivia Watkins, Nivedita Brett, Nikhil Vyas, Miles Wang, Michihiro Yasunaga, Michelle Pokrass, Mia Glaese, Max Schwarzer, Mark Chen, Mario Lezcano-Casado, Marat Dukhan, Lukas Gross, Ludovic Peran, Ludovic Peran, Lindsay McCallum, Lin Yang, Lily (Xiaoxuan) Liu, Leher Pathak, Lama Ahmad, Kristian Georgiev, Kristen Ying, Kimmy Richardson, Kevin Whinnery, Kevin Weil, Kevin Lu, Kevin Fives, Kendal Simon, Katia Gil Guzman, Karan Singhal, Karan Singhal, Kai Chen, Josh McGrath, Jordan Liss, Jongsoo Park, John Hallman, Johannes Heidecke, Jiancheng Liu, Ji Lin, Jason Kwon, Jason Ai, James Park Lennon, Jakub Pachocki, Jacob Huh, Jackie Hehir, Irina Kofman, Huida Qiu, Hongyu Ren, Harshit Sikchi, Hannah Wong, Haitang Hu, Haitang Hu, Haiming Bao, Hadi Salman, Guillaume Leclerc, Greg Brockman, Gideon Myles, Giambattista Parascandolo, Gaby Raila, Foivos Tsimpourlas, Filippo Raso, Eugene Brevdo, Eric Wallace, Enoch Cheung, Elizabeth Proehl, Elaine Ya Le, Edwin Arbus, Eddie Zhang, Dominik Kundel, Dmitry Pimenov, David Robinson, Dane Stuckey, Dana Palmie, Dan Cook, Cyril Zhang, Chris Lu, Chris Koch, Che Chang, Cedric Whitney, Casey Dvorak, Carolina Paz, Brian Zhang, Bowen Baker, Bob Rotsted, Boaz Barak, Ashley Pantuliano, Andy Applebaum, Amy Wendling, Ally Bennett, Alexander Neitz, Alex Paino, Alex Nichol, Alec Helyar, Aidan McLaughlin, Aidan Clark, Adam Goucher\n## Keep reading\n[View all](https://openai.com/news/release/)\n![GPT-5 Dev > Cover Image](https://images.ctfassets.net/kftzwdyauwt9/1nXq4baBEWkp6AjB42QJ3h/922de09f114a96a374af2ce0bbf9c99d/GPT_5_Dev_1x1.png?w=3840&q=90&fm=webp)\n[\nIntroducing GPT-5 for developers\nProductAug 7, 2025\n](https://openai.com/index/introducing-gpt-5-for-developers/)\n![GPT-5 Enterprise > Cover Image](https://images.ctfassets.net/kftzwdyauwt9/6aFpkPOhGqKgVQeh8uYJdv/722e57ac262e25fb79f4018651f5574d/GPT-5_EntBlog_ArtCard_1x1.png?w=3840&q=90&fm=webp)\n[\nGPT-5 and the new era of work\nProductAug 7, 2025\n](https://openai.com/index/gpt-5-new-era-of-work/)\n![GPT-5 SafetyReport ArtCard 1x1](https://images.ctfassets.net/kftzwdyauwt9/76ITD07iGdB0bhFga2x2G1/70f3ed29dbe3ff0acb0c2510a73c63e0/GPT-5_SafetyReport_ArtCard_1x1.png?w=3840&q=90&fm=webp)\n[\nFrom hard refusals to safe-completions: toward output-centric safety training\nSafetyAug 7, 2025\n](https://openai.com/index/gpt-5-safe-completions/)\nOur Research\n-   [Research Index](https://openai.com/research/index/)\n-   [Research Overview](https://openai.com/research/)\n-   [Research Residency](https://openai.com/residency/)\nLatest Advancements\n-   [OpenAI o3](https://openai.com/index/introducing-o3-and-o4-mini/)\n-   [OpenAI o4-mini](https://openai.com/index/introducing-o3-and-o4-mini/)\n-   [GPT-4o](https://openai.com/index/gpt-4o-system-card/)\n-   [GPT-4o mini](https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/)\n-   [Sora](https://openai.com/index/sora-system-card/)\nSafety\n-   [Safety Approach](https://openai.com/safety/)\n-   [Security & Privacy](https://openai.com/security-and-privacy/)\n-   [Trust & Transparency](https://openai.com/trust-and-transparency/)\nChatGPT\n-   [Explore ChatGPT](https://openai.com/chatgpt/overview/)\n-   [Team](https://openai.com/chatgpt/team/)\n-   [Enterprise](https://openai.com/chatgpt/enterprise/)\n-   [Education](https://openai.com/chatgpt/education/)\n-   [Pricing](https://openai.com/chatgpt/pricing/)\n-   [Download(opens in a new window)](https://chatgpt.com/download?openaicom-did=320ed580-3b1d-41d6-8e48-279d35b63921&openaicom_referred=true)\nSora\n-   [Sora Overview](https://openai.com/sora/)\n-   [Features](https://openai.com/sora/#features)\n-   [Pricing](https://openai.com/sora/#pricing)\n-   [Sora log in(opens in a new window)](https://sora.com/)\nAPI Platform\n-   [Platform Overview](https://openai.com/api/)\n-   [Pricing](https://openai.com/api/pricing/)\n-   [API log in(opens in a new window)](https://platform.openai.com/login)\n-   [Documentation(opens in a new window)](https://platform.openai.com/docs/overview)\n-   [Developer Forum(opens in a new window)](https://community.openai.com/)\nFor Business\n-   [Business Overview](https://openai.com/business/)\n-   [Solutions](https://openai.com/solutions/)\n-   [Contact Sales](https://openai.com/contact-sales/)\nCompany\n-   [About Us](https://openai.com/about/)\n-   [Our Charter](https://openai.com/charter/)\n-   [Careers](https://openai.com/careers/)\n-   [Brand](https://openai.com/brand/)\nSupport\n-   [Help Center(opens in a new window)](https://help.openai.com/)\nMore\n-   [News](https://openai.com/news/)\n-   [Stories](https://openai.com/stories/)\n-   [Livestreams](https://openai.com/live/)\n-   [Podcast](https://openai.com/podcast/)\nTerms & Policies\n-   [Terms of Use](https://openai.com/policies/terms-of-use/)\n-   [Privacy Policy](https://openai.com/policies/privacy-policy/)\n-   [Other Policies](https://openai.com/policies/)\n[(opens in a new window)](https://x.com/OpenAI)[(opens in a new window)](https://www.youtube.com/OpenAI)[(opens in a new window)](https://www.linkedin.com/company/openai)[(opens in a new window)](https://github.com/openai)[(opens in a new window)](https://www.instagram.com/openai/)[(opens in a new window)](https://www.tiktok.com/@openai)[(opens in a new window)](https://discord.gg/openai)\nOpenAI © 2015–2025Manage Cookies\nEnglishUnited States",
  "timestamp": 1754619321490,
  "title": "Introducing gpt-oss | OpenAI"
}